#!/usr/bin/env python

# Copyright (c) 2015, Jake Cheuvront, Chris Lalancette
# All rights reserved.

# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:

# 1. Redistributions of source code must retain the above copyright notice,
# this list of conditions and the following disclaimer.

# 2. Redistributions in binary form must reproduce the above copyright notice,
# this list of conditions and the following disclaimer in the documentation
# and/or other materials provided with the distribution.

# 3. Neither the name of the copyright holder nor the names of its contributors
# may be used to endorse or promote products derived from this software without
# specific prior written permission.

# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.

import sys
import os
import hashlib
import json
import fnmatch
import requests
import pycurl
import dulwich.porcelain
import errno
import requests_toolbelt.multipart.encoder
import httplib
import re
import paramiko
import urlparse
import getpass
import getopt
import logging

def print_transfer_string(transferred, total, filename, direction):
  if total > 1073741824:
    suffix = "GB"
    divider = 1073741824
  elif total > 1048576:
    suffix = "MB"
    divider = 1048576
  elif total > 1024:
    suffix = "KB"
    divider = 1024
  else:
    suffix = "bytes"
    divider = 1

  divided_tran = int(transferred / divider)
  divided_total = int(total / divider)
  percent = int(transferred * 100 / total)
  strlen_no_file = len(direction) + 1 + 1 + len(str(divided_tran)) + 1 + len(str(divided_total)) + 1 + len(suffix) + 2 + 3 + 2

  filenamelen = len(filename)
  if strlen_no_file + len(filename) > 80:
    filenamelen = 80 - strlen_no_file

  sys.stdout.write("\r")
  sys.stdout.write("{0} {1:.{2}s} {3}/{4} {5} ({6}%)".format(direction,
                                                             filename,
                                                             filenamelen,
                                                             divided_tran,
                                                             divided_total,
                                                             suffix, percent))

  sys.stdout.flush()

class SCP(object):
  def __init__(self, configuration):
    self.direction = "Downloading"
    self.filename = "Unset"
    self.configuration = configuration

  def _print_total(self, transferred, total):
    print_transfer_string(transferred, total, self.filename, self.direction)

  def _get_location_info_scp(self):
    parser = urlparse.urlparse(self.configuration['remote'])
    username = parser.username
    if username is None:
      username = getpass.getuser()
    return (parser.hostname, parser.path, username)

  def load(self, filename, checksum):
    logging.debug("load_scp")
    (hostname, remote_dir, username) = self._get_location_info_scp()
    logging.debug("hostname: %s, remote_dir: %s, username: %s" % (hostname,
                                                                  remote_dir,
                                                                  username))
    ssh = paramiko.SSHClient()
    ssh.load_host_keys(os.path.expanduser(os.path.join("~", ".ssh", "known_hosts")))
    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    ssh.connect(hostname, username=username)
    sftp = ssh.open_sftp()
    sftp.chdir(remote_dir)
    remotefile = '%s.got' % (checksum)
    self.direction = "Downloading"
    self.filename = filename
    sftp.get(remotefile, filename, callback=self._print_total)
    sys.stdout.write("\n")
    sftp.close()
    ssh.close()

  def store(self, filename, checksum):
    logging.debug("store_scp")
    (hostname, remote_dir, username) = self._get_location_info_scp()
    logging.debug("hostname: %s, remote_dir: %s, username: %s" % (hostname,
                                                                  remote_dir,
                                                                  username))
    ssh = paramiko.SSHClient()
    ssh.load_host_keys(os.path.expanduser(os.path.join("~", ".ssh", "known_hosts")))
    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    ssh.connect(hostname, username=username)
    sftp = ssh.open_sftp()
    sftp.chdir(remote_dir)
    remotefile = '%s.got' % (checksum)

    # here we do an optimization; if the remote file with the right filename
    # already exists, we don't need to upload it again.  Just get out of here
    try:
      sftp.stat(remotefile)
      logging.debug("File existed on remote, skipping upload...")
      sftp.close()
      ssh.close()
      return
    except IOError:
      logging.debug("Uploading file to remote...")

    self.direction = "Uploading"
    self.filename = filename
    sftp.put(filename, remotefile, callback=self._print_total)
    sys.stdout.write("\n")
    sftp.close()
    ssh.close()

  def version(self):
    return self.configuration['version']

class SRR(object):
  def __init__(self, configuration):
    self.last_mb = -1
    self.filename = "Unset"
    self.configuration = configuration
    self.upload_len = -1

  def _get_location_info_srr(self):
    parser = urlparse.urlparse(self.configuration['remote'])
    return (parser.hostname, os.path.basename(parser.path))

  def upload_cb(self, monitor):
    print_transfer_string(monitor.bytes_read, self.upload_len, self.filename,
                          "Uploading")

  def store(self, filename, checksum):
    logging.debug("store_srr")
    (server_name, parent_id) = self._get_location_info_srr()
    local_path = filename
    target_id = ''
    remote_path = '%s' % checksum
    description = 'Got storage for %s @ TBD hashtag' % (filename)

    # first check to see if the file already exists in the SRR
    conn = httplib.HTTPConnection(server_name)
    conn.request("GET", "/srr/api/file_metadata/sha256/%s" % checksum)
    response = conn.getresponse()
    conn.close()
    if response.status == 200:
      logging.debug("File existed on remote, skipping upload...")
      return

    # if the response was 404, the object was not in the store and thus we need
    # to upload it
    logging.debug("Uploading file to remote...")

    e = requests_toolbelt.multipart.encoder.MultipartEncoder(fields={
      'parent_id' : parent_id,
      'target_id' : '',
      'description' : description,
      'file' : (checksum, open(filename, 'rb'), 'application/octet-stream')})
    self.upload_len = len(e)
    self.filename = filename
    m = requests_toolbelt.multipart.encoder.MultipartEncoderMonitor(e,
                                                                    self.upload_cb)

    response = requests.post('http://%s/srr/api/add_file' % server_name, data = m, headers = {'Content-Type' : m.content_type})

    if response.status_code != 200:
      raise SRRError("%s: %s" % (response.reason, result))
    sys.stdout.write("\n")
    new_id_re = re.compile(r' file_id=(\d+)\s*$')
    m = new_id_re.search(response.text)
    if m:
      return int(m.group(1))
    else:
      raise SRRError("Unexpected result from SRR: %s" % result)

  def _get_remote_path_srr(self, server, checksum):
    response = requests.get('http://%s/srr/api/file_metadata/sha256/%s' % (server, checksum))
    return response.json()['url']

  def _curlprogress(self, down_total, down_current, up_total, up_current):
    if down_total == 0:
      return

    current_mb = int(down_current) / 1048576
    if current_mb > self.last_mb or down_current == down_total:
      self.last_mb = current_mb
      print_transfer_string(down_current, down_total, self.filename,
                            "Downloading")

  def load(self, filename, checksum):
    logging.debug("load_srr")
    (server, parent_id) = self._get_location_info_srr()

    path = self._get_remote_path_srr(server, checksum)
    logging.debug("load_srr, filename %s, path %s" % (filename, path))

    self.last_mb = -1
    self.filename = filename
    with open(filename, 'wb') as f:
      c = pycurl.Curl()
      c.setopt(c.URL, path)
      c.setopt(c.WRITEDATA, f)
      c.setopt(c.NOPROGRESS, 0)
      c.setopt(c.PROGRESSFUNCTION, self._curlprogress)
      c.perform()
      c.close()

    sys.stdout.write("\n")

  def version(self):
    return self.configuration['version']

class File(object):
  def __init__(self, configuration):
    self.configuration = configuration
    self.block_size = 8192

  def _transfer(self, srcpath, dstpath, direction):
    print_fname = srcpath
    if direction == "Downloading":
      print_fname = dstpath

    src = open(srcpath, "rb")
    dst = open(dstpath, "wb")

    total_len = os.fstat(src.fileno()).st_size
    transferred = 0

    while True:
      block = src.read(self.block_size)

      if not block:
        # end of file
        break
      else:
        dst.write(block)

      print_transfer_string(transferred, total_len, print_fname, direction)
      transferred += self.block_size

    print_transfer_string(total_len, total_len, print_fname, direction)
    sys.stdout.write("\n")
    dst.close()
    src.close()

  def store(self, filename, checksum):
    logging.debug("store_file")
    parser = urlparse.urlparse(self.configuration['remote'])
    dstpath = os.path.join(parser.path, checksum + ".got")
    if os.path.exists(dstpath):
      logging.debug("File existed on remote, skipping upload...")
      return

    self._transfer(filename, dstpath, "Uploading")

  def load(self, filename, checksum):
    logging.debug("load_file")
    parser = urlparse.urlparse(self.configuration['remote'])

    self._transfer(os.path.join(parser.path, checksum + ".got"), filename,
                   "Downloading")

  def version(self):
    return self.configuration['version']

def usage():
  print("git got <command> [<args>]")
  print("")
  print("The available git got commands are:")
  print("  init <type> <url>   Initialize the remote to be used with the repository,")
  print("                      where <type> is one of 'scp', 'srr', or 'file'.")
  print("  get [<file>...]     With no arguments, retrieve all remote files to the local")
  print("                      working area.  With one or more arguments, retrieve just")
  print("                      those remote files to the local working area.")
  print("  add <file>...       Add one or more files to the remote repository.  Note")
  print("                      that directories are not allowed.")
  print("  status [<file>...]  With no arguments, request the status of all got")
  print("                      tracked files.  With one or more arguments, request")
  print("                      just the status of the named files.")
  print("  reset <file>...     Overwrite one or more local got files with the remote")
  print("                      copy.  Note that directories are not allowed.")

def git_add(repo, filename):
  """
  Add a file to the git database.

  @param repo      Dulwich repository object
  @param filename  The file to add to the git database
  """
  logging.debug('git_add: Adding file %s to %s' % (filename, repo))
  dulwich.porcelain.add(repo, filename)

def file_hash(filename):
  """
  Hash the contents of the specified file using SHA-256 and return the hash
  as a string.

  @param filename  The filename to hash the contents of
  @return String representing the SHA-256 hash of the file contents
  """
  hasher = hashlib.sha256()
  with open(filename, 'rb') as infp:
    while True:
      data = infp.read(8192)
      if not data:
        break
      hasher.update(data)
  return hasher.hexdigest()

def get_cb(repo, got_filename, real_filename):
  """
  Fetches the specified file from the remote if necessary.

  @param repo           Dulwich repository object
  @param got_filename   Got meta filename
  @param real_filename  Real filename
  """
  try:
    logging.debug('get_cb: Using %s for local file' % real_filename)
    if status_local(got_filename, real_filename):
      logging.debug("File already exists, and has right checksum; skipping download...")
      return
    logging.debug("Downloading remote file...")
    remote_obj.load(real_filename, open(got_filename).read().rstrip())
  except Exception as e:
    logging.error('Failed to retrieve file %s: %s' % (real_filename, str(e)))

def reset_cb(repo, got_filename, real_filename):
  """
  Resets the specified file to the version from the got database, re-downloading
  it from the remote if necessary.

  @param repo           Dulwich repository object
  @param got_filename   Got meta filename
  @param real_filename  Real filename
  """
  try:
    logging.debug('reset_cb: Resetting %s' % real_filename)
    if status_local(got_filename, real_filename):
      logging.debug("File already exists locally, no need for work")
      return
    logging.debug('reset_cb: Using %s for local got file' % got_filename)
    remote_obj.load(real_filename, open(got_filename).read().rstrip())
  except Exception as e:
    logging.error('Failed to reset %s: %s' % (real_filename, str(e)))

def add_cb(repo, got_filename, real_filename):
  """
  Adds a new file to the got database and uploads it to the remote.

  @param repo           Dulwich repository object
  @param got_filename   Got meta filename
  @param real_filename  Real filename
  """
  try:
    logging.debug('add_cb: Adding %s' % real_filename)
    csum = file_hash(real_filename)
    remote_obj.store(real_filename, csum)
    with open(got_filename, 'w') as hash_file:
      hash_file.write('%s' % csum)
    git_add(repo, got_filename)
    with open('.gitignore', 'a') as gitignorefile:
      gitignorefile.write('%s\n' % real_filename)
    git_add(repo, '.gitignore')
  except Exception as e:
    logging.error('Failed to add %s: %s' % (real_filename, str(e)))

def status_local(got_filename, real_filename):
  """
  Determines if there are local changes made to the file specified in the
  filename parameter.

  @param got_filename   Got meta filename
  @param real_filename  Real filename
  @return True if The file is unchanged, False if the file is changed or not found
  """
  try:
    if not os.path.exists(real_filename):
      logging.debug('status_local: Did not find file %s' % real_filename)
      return False
    sum1 = file_hash(real_filename)
    sum2 = open(got_filename).read().rstrip()
    if sum1 != sum2:
      logging.debug('status_local: Got hash %s != file hash %s' % (sum1, sum2))
      return False
    return True
  except Exception as e:
    logging.error('status_local: Failed to status %s' % real_filename, e)
    return False

def status_cb(repo, got_filename, real_filename):
  """
  Retrieves the status of the filename specified.  Invoked from the main
  walker loop.

  @param repo           Dulwich repository object
  @param got_filename   Got meta filename
  @param real_filename  Real filename
  """
  try:
    if not os.path.exists(real_filename):
      return 'Missing locally: %s' % real_filename
    if not status_local(got_filename, real_filename):
      return 'Modified: %s' % real_filename
  except Exception as e:
    logging.error('Failed to get status of %s: %s' % (real_filename, str(e)))

def upgrade_cb(new):
  pass

def walker(function, repo, origpath, args):
  """
  A function to walk down a list of files/directories, calling a callback on
  each one.  The callback is expected to have a signature of:

  cb(repo, got_filename, real_filename)

  @param function  The function to call on each got managed file
  @param repo      Dulwich repository object to pass into the callback
  @param origpath  The original current working directory when got was invoked,
                   used to figure out the appropriate paths
  @param args      The list of files/directories to walk

  @return A string built from the output of all invocations of the callback
          function.
  """
  output = []
  logging.debug("walker: args: " + str(args))
  for arg in args:
    fullpath = os.path.normpath(os.path.join(origpath, arg))
    logging.debug('walker: processing argument %s' % fullpath)
    if os.path.isdir(fullpath):
      for base, dirs, filenames in os.walk(fullpath):
        if '.git' in dirs:
          dirs.remove('.git')
        if '.got' in dirs:
          dirs.remove('.got')
        for filename in fnmatch.filter(filenames, '.*.got'):
          realpath = os.path.normpath(os.path.join(base, filename[1:-4]))
          gotpath = os.path.normpath(os.path.join(base, filename))
          logging.debug('walker: processing file %s' % realpath)
          output.append(function(repo, gotpath, realpath))
    else:
      # this covers both the case where the argument is a file and the case
      # where the full path isn't a file at all (which can happen if the local
      # version of the file was deleted)
      logging.debug('walker: processing file %s' % fullpath)
      (base, filename) = os.path.split(fullpath)
      output.append(function(repo, os.path.join(base, '.%s.got' % filename), fullpath))
  return output

remote_obj = None

def check_initialized():
  """
  Function to look for got initialization, and open up the configuration if
  found.

  @return True if the got configuration file was found, False otherwise
  """
  global remote_obj
  if os.path.isfile('.got/storage'):
    with open('.got/storage', 'r') as storagefp:
      configuration = json.load(storagefp)
    if configuration['remote_type'] == 'srr':
      remote_obj = SRR(configuration)
    elif configuration['remote_type'] == 'file':
      remote_obj = File(configuration)
    else:
      remote_obj = SCP(configuration)
    return True
  return False

def check_version(version):
  return VERSION == remote_obj.version()

VERSION = 1

def mkdir_p(path):
  """
  Function to make a directory and all intermediate directories as
  necessary.  The functionality differs from os.makedirs slightly, in
  that this function does *not* raise an error if the directory already
  exists.

  @param path  The directory path to create
  """
  if path is None:
    raise Exception("Path cannot be None")

  if path == '':
    # this can happen if the user did something like call os.path.dirname()
    # on a file without directories.  Since os.makedirs throws an exception
    # in that case, check for it here and allow it.
    return

  try:
    os.makedirs(path)
  except OSError as err:
    if err.errno != errno.EEXIST or not os.path.isdir(path):
      raise

def find_git_path_and_chdir():
  """
  This function is expected to be called at the beginning and goes looking
  for the closest .git subdirectory or file in the filesystem hierarchy.
  We look for the .git subdirectory by first looking in ./.git, then changing
  directory to .. and looking for .git, etc, until we either find a .git
  directory or until we hit / (at which point we raise an error).  At the end
  we have changed directory to the appropriate level, which is similar to how
  git itself operates.  Assuming we succeed, this function returns a relative
  path to the original path we started out in so that subsequent operations
  (that may git add) can do the right thing.
  """
  origpath = os.getcwd()
  curpath = origpath
  while not os.path.exists(os.path.join(curpath, '.git')) and curpath != '/':
    os.chdir("..")
    curpath = os.getcwd()

  if curpath == '/':
    raise Exception, "Could not find git repository"

  # OK, we found the .git directory/file.  Now return the original path
  # relative to that found directory
  return os.path.relpath(origpath, os.path.commonprefix([origpath, os.getcwd()]))

def main(argv):
  loglevel = logging.ERROR
  logformat = "%(message)s"
  try:
    opts, args = getopt.gnu_getopt(argv[1:], 'd:h', ['debug', 'help'])
  except getopt.GetoptError as err:
    print(str(err))
    usage()
    return 1

  for o, a in opts:
    if o in ("-d", "--debug"):
      try:
        d_int = int(a)
      except ValueError:
        usage()
        return 1

      if d_int == 0:
        loglevel = logging.ERROR
      elif d_int == 1:
        loglevel = logging.WARNING
      elif d_int == 2:
        loglevel = logging.INFO
      elif d_int == 3:
        loglevel = logging.DEBUG
      elif d_int >= 4:
        loglevel = logging.DEBUG
        logformat = logging.BASIC_FORMAT
    elif o in ("-h", "--help"):
      usage()
      return 0
    else:
      assert False, "unhandled option"

  logging.basicConfig(level=loglevel, format=logformat)

  try:
    origpath = find_git_path_and_chdir()
  except Exception as e:
    logging.error("Failed to initialize git-got: %s" % (str(e)))
    return 1

  try:
    repo = dulwich.porcelain.open_repo(".")
  except Exception as e:
    logging.error(str(e))
    return 1

  command = args[0]

  # For bootstrapping purposes we have to check if the command is "init" first.
  if command == 'init':
    if len(args) != 3:
      usage()
      return 1

    remote_type = args[1]
    if remote_type != 'srr' and remote_type != 'scp' and remote_type != 'file':
      usage()
      return 1

    # here, make sure we don't blow away an already configuration got repository
    if os.path.isfile('.got/storage'):
      print('Got backend already initialized!')
      return 1

    remote = args[2]
    mkdir_p('.got')
    configuration = { 'remote' : remote , 'remote_type' : remote_type , 'version' : VERSION }
    with open('.got/storage', 'w') as storagefile:
      json.dump(configuration, storagefile)
    git_add(repo, '.got/storage')
    return 0

  if not check_initialized():
    print('Got not initialized\n')
    usage()
    return 1

  # If an upgrade is required, it really needs to be before we check the
  # version or we have a chicken and egg problem.
  if command == 'upgrade':
    if len(args) != 1:
      usage()
      return 1

    upgrade_cb(VERSION)
    return 0

  if not check_version(VERSION):
    print('Version of got repository requires upgrading, run upgrade command')
    usage()
    return 1

  if command == 'add':
    if len(args) < 2:
      usage()
      return 1

    # we only allow adding files (not subdirectories); check that here
    for arg in args[1:]:
      if not os.path.isfile(os.path.join(origpath, arg)):
        print("git-got only allows files, not subdirectories, to be added")
        usage()
        return 1

    walker(add_cb, repo, origpath, args[1:])

    return 0
  elif command == 'reset':
    if len(args) < 2:
      usage()
      return 1

    # we only allow resetting files (not subdirectories); check that here
    for arg in args[1:]:
      if not os.path.isfile(os.path.join(origpath, arg)):
        print("git-got only allows files, not subdirectories, to be reset")
        usage()
        return 1

    walker(reset_cb, repo, origpath, args[1:])
    return 0
  elif command == 'get':
    if len(args) == 1:
      path = ['.']
    elif len(args) > 1:
      path = args[1:]
    else:
      usage()
      return 1

    walker(get_cb, repo, origpath, path)
    return 0
  elif command == 'status':
    if len(args) == 1:
      path = ['.']
    elif len(args) > 1:
      path = args[1:]
    else:
      usage()
      return 1

    changes = walker(status_cb, repo, origpath, path)
    print('# Changes')
    for change in changes:
      if None != change:
        print('# %s' % change)
    return 0
  else:
    usage()
    return 1

if __name__ == "__main__":
  exit(main(sys.argv))

# vim: set filetype=python :
